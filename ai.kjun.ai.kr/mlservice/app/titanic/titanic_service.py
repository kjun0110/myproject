import pandas as pd
import numpy as np
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
import logging
import os
from pathlib import Path
from typing import Optional, List, Dict, Any
from titanic.titanic_method import TitanicMethod
from titanic.titanic_dataset import TitanicDataSet

logger = logging.getLogger(__name__)

# LightGBM import (ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©)
try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except (ImportError, OSError) as e:
    logger.error(f"LightGBM import ì‹¤íŒ¨: {e}")
    logger.error("LightGBMì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ê±°ë‚˜ í•„ìš”í•œ ì‹œìŠ¤í…œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
    logger.error("Dockerfileì— 'RUN apt-get update && apt-get install -y libgomp1' ì¶”ê°€ í•„ìš”")
    LIGHTGBM_AVAILABLE = False
    # ë”ë¯¸ ê°ì²´ ìƒì„± (ì—ëŸ¬ ë°©ì§€)
    class DummyLGBM:
        def __init__(self, *args, **kwargs):
            pass
    lgb = type('lgb', (), {'LGBMClassifier': DummyLGBM})()


class PassengerService:
    """Titanic Passenger CRUD ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        # CSV íŒŒì¼ ê²½ë¡œ ì„¤ì •
        current_file = Path(__file__).resolve()
        # app/titanic/titanic_service.py -> app/titanic/ (ê°™ì€ ë””ë ‰í† ë¦¬)
        titanic_dir = current_file.parent
        self.train_csv_path = titanic_dir / "train.csv"
        self.test_csv_path = titanic_dir / "test.csv"
        # ì „ì²˜ë¦¬ëœ ë°ì´í„°ì™€ ëª¨ë¸ ì €ì¥
        self.processed_data = None
        self.models = {}
        self.y_train = None
    
    def _get_csv_path(self, filename: str) -> Path:
        """
        CSV íŒŒì¼ì˜ ì „ì²´ ê²½ë¡œë¥¼ ë°˜í™˜
        
        Args:
            filename: CSV íŒŒì¼ëª… (train.csv ë˜ëŠ” test.csv)
        
        Returns:
            CSV íŒŒì¼ì˜ Path ê°ì²´
        """
        if filename == "train.csv":
            return self.train_csv_path
        elif filename == "test.csv":
            return self.test_csv_path
        else:
            # ê¸°ë³¸ì ìœ¼ë¡œ titanic í´ë”ì—ì„œ ì°¾ê¸°
            current_file = Path(__file__).resolve()
            titanic_dir = current_file.parent
            return titanic_dir / filename

    def preprocess(self) -> Dict[str, Any]:
        logger.info("ğŸ¦ğŸ¦ì „ì²˜ë¦¬ ì‹œì‘")
        the_method = TitanicMethod()

        #train
        train_csv_path = self._get_csv_path('train.csv')
        df_train = the_method.read_csv(str(train_csv_path))
        # Survived label ì €ì¥
        self.y_train = df_train['Survived']
        this_train = the_method.create_df(df_train, 'Survived')
        logger.info(f"Train CSV íŒŒì¼ ê²½ë¡œ: {train_csv_path}")
        logger.info(f'1. Train ì˜ type \n {type(this_train)} ')
        logger.info(f'2. Train ì˜ column \n {this_train.columns} ')
        logger.info(f'3. Train ì˜ ìƒìœ„ 5ê°œ í–‰\n {this_train.head(5)} ')
        logger.info(f'4. Train ì˜ null ì˜ ê°¯ìˆ˜\n {this_train.isnull().sum().sum()}ê°œ')

        #test
        test_csv_path = self._get_csv_path('test.csv')
        df_test = the_method.read_csv(str(test_csv_path))
        this_test = the_method.create_df(df_test, 'Survived')
        logger.info(f"Test CSV íŒŒì¼ ê²½ë¡œ: {test_csv_path}")
        logger.info(f'1. Test ì˜ type \n {type(this_test)} ')
        logger.info(f'2. Test ì˜ column \n {this_test.columns} ')
        logger.info(f'3. Test ì˜ ìƒìœ„ 5ê°œ í–‰\n {this_test.head(5)} ')
        logger.info(f'4. Test ì˜ null ì˜ ê°¯ìˆ˜\n {this_test.isnull().sum().sum()}ê°œ')
        
        this = TitanicDataSet()

        this.train = this_train
        this.test = this_test

        drop_features = ['SibSp', 'Parch', 'Cabin', 'Ticket']
        this = the_method.drop_feature(this, *drop_features)
        this = the_method.pclass_ordinal(this)
        this = the_method.title_nominal(this)
        this = the_method.gender_nominal(this)
        this = the_method.age_ratio(this)
        this = the_method.fare_ordinal(this)
        this = the_method.embarked_ordinal(this)
        drop_name = ['Name']
        this = the_method.drop_feature(this, *drop_name)

        # ì „ì²˜ë¦¬ í›„ null í™•ì¸
        the_method.check_null(this)
        
        logger.info("ğŸ¦ğŸ¦ train ì „ì²˜ë¦¬ ì™„ë£Œ")
        logger.info(f'1. Train ì˜ type \n {type(this.train)} ')
        logger.info(f'2. Train ì˜ column \n {this.train.columns} ')
        logger.info(f'3. Train ì˜ ìƒìœ„ 5ê°œ í–‰\n {this.train.head(5)} ')
        logger.info(f'4. Train ì˜ null ì˜ ê°¯ìˆ˜\n {this.train.isnull().sum().sum()}ê°œ')

        logger.info("ğŸ¦ğŸ¦ test ì „ì²˜ë¦¬ ì™„ë£Œ")
        logger.info(f'1. Test ì˜ type \n {type(this.test)}')
        logger.info(f'2. Test ì˜ column \n {this.test.columns}')
        logger.info(f'3. Test ì˜ ìƒìœ„ 5ê°œ í–‰\n {this.test.head(5)}')
        logger.info(f'4. Test ì˜ null ì˜ ê°¯ìˆ˜\n {this.test.isnull().sum().sum()}ê°œ')

        # JSON ì‘ë‹µì„ ìœ„í•œ ë°ì´í„° ë³€í™˜
        import math
        def safe_convert(value):
            """NaN, inf ê°’ì„ JSON í˜¸í™˜ ê°’ìœ¼ë¡œ ë³€í™˜"""
            if pd.isna(value):
                return None
            if isinstance(value, (np.integer, np.floating)):
                if math.isnan(value) or math.isinf(value):
                    return None
                return float(value) if isinstance(value, np.floating) else int(value)
            return value
        
        def clean_dict(d):
            """ë”•ì…”ë„ˆë¦¬ì˜ ëª¨ë“  ê°’ì„ ì•ˆì „í•˜ê²Œ ë³€í™˜"""
            if isinstance(d, dict):
                return {k: clean_dict(v) for k, v in d.items()}
            elif isinstance(d, list):
                return [clean_dict(item) for item in d]
            else:
                return safe_convert(d)
        
        def df_to_dict(df, head_rows=5):
            head_data = df.head(head_rows).to_dict(orient='records')
            return {
                "head": clean_dict(head_data),
                "columns": df.columns.tolist(),
                "shape": {"rows": int(df.shape[0]), "columns": int(df.shape[1])},
                "null_counts": {col: int(count) for col, count in df.isnull().sum().items()}
            }
        
        # ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥
        self.processed_data = this
        
        return {
            "message": "ì „ì²˜ë¦¬ ì™„ë£Œ",
            "train": df_to_dict(this.train),
            "test": df_to_dict(this.test)
        }

    def modeling(self):
        logger.info("ğŸ¦ğŸ¦ëª¨ë¸ë§ ì‹œì‘")

        if self.processed_data is None:
            logger.warning("ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € preprocess()ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
            return
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.models = {
            'logistic_regression': LogisticRegression(random_state=42, max_iter=1000),
            'naive_bayes': GaussianNB(),
            'random_forest': RandomForestClassifier(n_estimators=100, random_state=42),
            'svm': SVC(random_state=42, probability=True)
        }
        
        # LightGBM ì¶”ê°€ (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
        if LIGHTGBM_AVAILABLE:
            self.models['lightgbm'] = lgb.LGBMClassifier(random_state=42, verbose=-1)
        else:
            # LightGBMì´ ì—†ì–´ë„ ê²°ê³¼ì— í¬í•¨ë˜ë„ë¡ ë”ë¯¸ ëª¨ë¸ ì¶”ê°€
            logger.warning("LightGBMì´ ì—†ìŠµë‹ˆë‹¤. ë”ë¯¸ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            class DummyLightGBMModel:
                def fit(self, X, y):
                    logger.warning("LightGBM ë”ë¯¸ ëª¨ë¸: fit í˜¸ì¶œë¨")
                    return self
                def predict(self, X):
                    logger.warning("LightGBM ë”ë¯¸ ëª¨ë¸: predict í˜¸ì¶œë¨")
                    return [0] * len(X)
            self.models['lightgbm'] = DummyLightGBMModel()
        
        logger.info(f"ğŸ¦ğŸ¦ëª¨ë¸ë§ ì™„ë£Œ - ì´ {len(self.models)}ê°œ ëª¨ë¸: {list(self.models.keys())}")

    def learning(self):
        logger.info("ğŸ¦ğŸ¦í•™ìŠµ ì‹œì‘")

        if self.processed_data is None or not self.models:
            logger.warning("ì „ì²˜ë¦¬ëœ ë°ì´í„°ë‚˜ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € preprocess()ì™€ modeling()ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
            return
        
        if self.y_train is None:
            logger.warning("í•™ìŠµìš© labelì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € preprocess()ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
            return
        
        X_train = self.processed_data.train.copy()
        y_train = self.y_train
        
        # PassengerIdê°€ ìˆìœ¼ë©´ ì œê±° (IDëŠ” í•™ìŠµì— ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
        if 'PassengerId' in X_train.columns:
            X_train = X_train.drop(columns=['PassengerId'])
            logger.info("PassengerId ì»¬ëŸ¼ì„ ì œê±°í–ˆìŠµë‹ˆë‹¤.")
        
        # ëª¨ë“  ì»¬ëŸ¼ì„ ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜ (object íƒ€ì… ì œê±°)
        for col in X_train.columns:
            if X_train[col].dtype == 'object':
                logger.warning(f"{col} ì»¬ëŸ¼ì´ object íƒ€ì…ì…ë‹ˆë‹¤. ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")
                X_train[col] = pd.to_numeric(X_train[col], errors='coerce').fillna(0).astype(int)
        
        logger.info(f"í•™ìŠµ ë°ì´í„° íƒ€ì…: {X_train.dtypes}")
        
        # ê° ëª¨ë¸ í•™ìŠµ
        for model_name, model in self.models.items():
            logger.info(f"{model_name} í•™ìŠµ ì¤‘...")
            try:
                model.fit(X_train, y_train)
                logger.info(f"{model_name} í•™ìŠµ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"{model_name} í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                raise
        
        logger.info("ğŸ¦ğŸ¦í•™ìŠµ ì™„ë£Œ")

    def evaluate(self) -> Dict[str, Any]:
        logger.info("ğŸ¦ğŸ¦í‰ê°€ ì‹œì‘")

        if self.processed_data is None or not self.models:
            logger.warning("ì „ì²˜ë¦¬ëœ ë°ì´í„°ë‚˜ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € preprocess(), modeling(), learning()ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
            return {"error": "ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
        
        if self.y_train is None:
            logger.warning("í•™ìŠµìš© labelì´ ì—†ìŠµë‹ˆë‹¤.")
            return {"error": "í•™ìŠµìš© labelì´ ì—†ìŠµë‹ˆë‹¤."}
        
        X_train = self.processed_data.train.copy()
        y_train = self.y_train
        
        # PassengerIdê°€ ìˆìœ¼ë©´ ì œê±° (IDëŠ” í•™ìŠµì— ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
        if 'PassengerId' in X_train.columns:
            X_train = X_train.drop(columns=['PassengerId'])
            logger.info("PassengerId ì»¬ëŸ¼ì„ ì œê±°í–ˆìŠµë‹ˆë‹¤.")
        
        # ëª¨ë“  ì»¬ëŸ¼ì„ ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜ (object íƒ€ì… ì œê±°)
        for col in X_train.columns:
            if X_train[col].dtype == 'object':
                logger.warning(f"{col} ì»¬ëŸ¼ì´ object íƒ€ì…ì…ë‹ˆë‹¤. ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")
                X_train[col] = pd.to_numeric(X_train[col], errors='coerce').fillna(0).astype(int)
        
        logger.info(f"í‰ê°€ ë°ì´í„° íƒ€ì…: {X_train.dtypes}")
        
        # Train ë°ì´í„°ë¥¼ train/validationìœ¼ë¡œ ë¶„í• 
        X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(
            X_train, y_train, test_size=0.2, random_state=42, stratify=y_train
        )
        
        # ê° ëª¨ë¸ ì¬í•™ìŠµ ë° í‰ê°€
        logger.info(f"í‰ê°€í•  ëª¨ë¸ ëª©ë¡: {list(self.models.keys())}")
        results = {}
        for model_name, model in self.models.items():
            logger.info(f"{model_name} ì¬í•™ìŠµ ë° í‰ê°€ ì¤‘...")
            try:
                # Validation setìœ¼ë¡œ ì¬í•™ìŠµ
                model.fit(X_train_split, y_train_split)
                # Validation setìœ¼ë¡œ ì˜ˆì¸¡
                y_pred = model.predict(X_val_split)
                accuracy = accuracy_score(y_val_split, y_pred)
                results[model_name] = float(accuracy)
                logger.info(f'{model_name} í™œìš©í•œ ê²€ì¦ ì •í™•ë„ {accuracy:.4f}')
            except Exception as e:
                logger.error(f"{model_name} í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                import traceback
                logger.error(traceback.format_exc())
                results[model_name] = None
        
        logger.info("ğŸ¦ğŸ¦í‰ê°€ ì™„ë£Œ")
        
        return {
            "message": "í‰ê°€ ì™„ë£Œ",
            "results": results
        }

    def postprocess(self):
        logger.info("ğŸ¦ğŸ¦í›„ì²˜ë¦¬ ì‹œì‘")
        logger.info("ğŸ¦ğŸ¦í›„ì²˜ë¦¬ ì™„ë£Œ")


    def submit(self, model_name: str = None) -> Dict[str, Any]:
        """
        Kaggle ì œì¶œ íŒŒì¼ ìƒì„±
        model_nameì´ Noneì´ë©´ ì •í™•ë„ê°€ ê°€ì¥ ë†’ì€ ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤.
        
        Args:
            model_name: ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„ (Noneì´ë©´ ìë™ ì„ íƒ)
                        'logistic_regression', 'naive_bayes', 'random_forest', 'lightgbm', 'svm'
        
        Returns:
            ì œì¶œ íŒŒì¼ ê²½ë¡œì™€ ì •ë³´
        """
        logger.info("ğŸ¦ğŸ¦ì œì¶œ ì‹œì‘")
        
        if self.processed_data is None or not self.models:
            logger.warning("ì „ì²˜ë¦¬ëœ ë°ì´í„°ë‚˜ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € preprocess(), modeling(), learning()ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
            return {"error": "ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
        
        # model_nameì´ Noneì´ë©´ ì •í™•ë„ê°€ ê°€ì¥ ë†’ì€ ëª¨ë¸ ìë™ ì„ íƒ
        if model_name is None:
            logger.info("ëª¨ë¸ì´ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì •í™•ë„ê°€ ê°€ì¥ ë†’ì€ ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤.")
            
            # ë¨¼ì € í‰ê°€ë¥¼ ì‹¤í–‰í•˜ì—¬ ê° ëª¨ë¸ì˜ ì •í™•ë„ í™•ì¸
            evaluation_result = self.evaluate()
            
            if "error" in evaluation_result:
                logger.warning("í‰ê°€ ì‹¤íŒ¨. ê¸°ë³¸ ëª¨ë¸(random_forest)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                model_name = 'random_forest'
            else:
                results = evaluation_result.get("results", {})
                if not results:
                    logger.warning("í‰ê°€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë¸(random_forest)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    model_name = 'random_forest'
                else:
                    # Noneì´ ì•„ë‹Œ ê²°ê³¼ ì¤‘ì—ì„œ ì •í™•ë„ê°€ ê°€ì¥ ë†’ì€ ëª¨ë¸ ì„ íƒ
                    valid_results = {k: v for k, v in results.items() if v is not None}
                    if not valid_results:
                        logger.warning("ìœ íš¨í•œ í‰ê°€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë¸(random_forest)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                        model_name = 'random_forest'
                    else:
                        best_model = max(valid_results.items(), key=lambda x: x[1])
                        model_name = best_model[0]
                        logger.info(f"ì •í™•ë„ê°€ ê°€ì¥ ë†’ì€ ëª¨ë¸ ì„ íƒ: {model_name} (ì •í™•ë„: {best_model[1]:.4f})")
        
        if model_name not in self.models:
            logger.error(f"ëª¨ë¸ '{model_name}'ì´ ì—†ìŠµë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {list(self.models.keys())}")
            return {"error": f"ëª¨ë¸ '{model_name}'ì´ ì—†ìŠµë‹ˆë‹¤."}
        
        # Test ë°ì´í„° ì¤€ë¹„
        X_test = self.processed_data.test.copy()
        
        # PassengerId ì €ì¥
        if 'PassengerId' not in X_test.columns:
            logger.error("PassengerId ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return {"error": "PassengerId ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤."}
        
        passenger_ids = X_test['PassengerId'].copy()
        X_test = X_test.drop(columns=['PassengerId'])
        
        # ëª¨ë“  ì»¬ëŸ¼ì„ ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜ (object íƒ€ì… ì œê±°)
        for col in X_test.columns:
            if X_test[col].dtype == 'object':
                logger.warning(f"{col} ì»¬ëŸ¼ì´ object íƒ€ì…ì…ë‹ˆë‹¤. ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")
                X_test[col] = pd.to_numeric(X_test[col], errors='coerce').fillna(0).astype(int)
        
        # Train ë°ì´í„°ë¡œ ëª¨ë¸ ì¬í•™ìŠµ
        X_train = self.processed_data.train.copy()
        y_train = self.y_train
        
        # PassengerId ì œê±°
        if 'PassengerId' in X_train.columns:
            X_train = X_train.drop(columns=['PassengerId'])
        
        # ëª¨ë“  ì»¬ëŸ¼ì„ ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜
        for col in X_train.columns:
            if X_train[col].dtype == 'object':
                X_train[col] = pd.to_numeric(X_train[col], errors='coerce').fillna(0).astype(int)
        
        # ëª¨ë¸ ì„ íƒ ë° í•™ìŠµ
        model = self.models[model_name]
        logger.info(f"{model_name} ëª¨ë¸ë¡œ ì „ì²´ í•™ìŠµ ë°ì´í„°ë¡œ ì¬í•™ìŠµ ì¤‘...")
        model.fit(X_train, y_train)
        logger.info(f"{model_name} ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
        
        # ì˜ˆì¸¡
        logger.info(f"{model_name} ëª¨ë¸ë¡œ ì˜ˆì¸¡ ì¤‘...")
        predictions = model.predict(X_test)
        logger.info(f"ì˜ˆì¸¡ ì™„ë£Œ: {len(predictions)}ê°œ")
        
        # ì œì¶œ íŒŒì¼ ìƒì„±
        submission_df = pd.DataFrame({
            'PassengerId': passenger_ids,
            'Survived': predictions.astype(int)
        })
        
        # kaggle í´ë”ì— ì €ì¥
        current_file = Path(__file__).resolve()
        kaggle_dir = current_file.parent.parent / "kaggle"
        kaggle_dir.mkdir(exist_ok=True)
        
        # íŒŒì¼ëª…: submission_{model_name}_{timestamp}.csv
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"submission_{model_name}_{timestamp}.csv"
        filepath = kaggle_dir / filename
        
        submission_df.to_csv(filepath, index=False)
        logger.info(f"ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ: {filepath}")
        logger.info(f"íŒŒì¼ í¬ê¸°: {len(submission_df)}í–‰")
        logger.info(f"ìƒì¡´ ì˜ˆì¸¡ ìˆ˜: {int(predictions.sum())}ëª…")
        
        logger.info("ğŸ¦ğŸ¦ì œì¶œ ì™„ë£Œ")
        
        # í‰ê°€ ê²°ê³¼ì—ì„œ ì„ íƒëœ ëª¨ë¸ì˜ ì •í™•ë„ ê°€ì ¸ì˜¤ê¸°
        evaluation_result = self.evaluate()
        model_accuracy = None
        if "results" in evaluation_result:
            model_accuracy = evaluation_result["results"].get(model_name)
        
        result = {
            "message": "ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ",
            "model": model_name,
            "filepath": str(filepath),
            "filename": filename,
            "total_passengers": int(len(submission_df)),
            "predicted_survived": int(predictions.sum()),
            "predicted_not_survived": int(len(predictions) - predictions.sum())
        }
        
        if model_accuracy is not None:
            result["model_accuracy"] = float(model_accuracy)
            result["auto_selected"] = (model_name is None or model_name == "auto")
        
        return result